{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean webtext from charter school data\n",
    "\n",
    "- Author: Jaren Haber, Madeleine Peng, James Jung\n",
    "- Institution: UC Berkeley\n",
    "- Date created: July 26, 2019\n",
    "- Date last edited: \n",
    "\n",
    "Description: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd # For working with DataFrames\n",
    "import gc # To accelerate loading pickle files\n",
    "import nltk\n",
    "# Show visualizations within notebook:\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load functions from data_tools directory:\n",
    "import sys; sys.path.insert(0, \"../tools\")\n",
    "\n",
    "# For displaying basic DF info, storing DFs for memory efficiency, and loading a filtered DF:\n",
    "from df_tools import check_df, convert_df, load_filtered_df, replace_df_nulls\n",
    "\n",
    "# For quickly loading & saving pickle files in Python:\n",
    "from quickpickle import quickpickle_dump, quickpickle_load \n",
    "\n",
    "# For saving and loading text lists to/from file:\n",
    "from textlist_file import write_list, load_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file paths\n",
    "charters_path = \"../../nowdata/charters_2015.pkl\"\n",
    "original_path = \"../../nowdata/backups/charters_full_2015_250_v2a_unlappedtext_counts3_geoleaid.pkl\"\n",
    "filtered_path = \"../../nowdata/parsing/filtered_10.pkl\"\n",
    "raw_folder = \"../../nowdata/webtext_raw/\" # for raw webtext when extracted\n",
    "raw_filtered_data = raw_folder + \"webtext_unlapped_filtered_10.tsv\"\n",
    "cleaned_folder = \"../../nowdata/webtext_cleaned/\" # for cleaned webtext: save as CSV, include ONLY the columns \"NCESSCH\" (unique school identifier) and \"text_full\" (renamed from \"WEBTEXT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import spacy and clean_text to test clean_sentence\n",
    "import spacy, clean_text\n",
    "from clean_text import clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 's',\n",
       " 'program',\n",
       " 'enrol',\n",
       " 'link',\n",
       " 'commun',\n",
       " 'contact',\n",
       " 'more',\n",
       " 'bennett',\n",
       " 'academi',\n",
       " 'high',\n",
       " 'begin',\n",
       " 'serv',\n",
       " 'student',\n",
       " 'th',\n",
       " 'th',\n",
       " 'grade',\n",
       " '',\n",
       " 'offer',\n",
       " 'followng',\n",
       " 'a',\n",
       " 'good',\n",
       " 'school',\n",
       " 'good',\n",
       " 'disciplin',\n",
       " 'a',\n",
       " 'well-organ',\n",
       " 'learn',\n",
       " 'environ',\n",
       " 'friendli',\n",
       " 'vibe',\n",
       " 'a',\n",
       " 'place',\n",
       " 'teacher',\n",
       " 'staff',\n",
       " 'student',\n",
       " 'treat',\n",
       " 'kindli',\n",
       " 'respect',\n",
       " 'an',\n",
       " 'environ',\n",
       " 'friend',\n",
       " 'add',\n",
       " 'good',\n",
       " 'friend',\n",
       " 'teacher',\n",
       " 'care',\n",
       " 'student',\n",
       " 'give',\n",
       " 'good',\n",
       " 'help',\n",
       " 'teach',\n",
       " 'need',\n",
       " 'core',\n",
       " 'class',\n",
       " 'sever',\n",
       " 'elect',\n",
       " 'sport',\n",
       " '',\n",
       " '',\n",
       " 'enrol',\n",
       " 'now',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'bmaster',\n",
       " '',\n",
       " 'herebi',\n",
       " 'state',\n",
       " 'notic',\n",
       " 'meet',\n",
       " 'post',\n",
       " 'administr',\n",
       " 'offic',\n",
       " 'websit',\n",
       " 'wwwbennettacademycom',\n",
       " 'the',\n",
       " 'locat',\n",
       " 'open',\n",
       " 'public',\n",
       " '',\n",
       " 'am',\n",
       " '',\n",
       " 'pm',\n",
       " 'such',\n",
       " 'notic',\n",
       " 'indic',\n",
       " 'date',\n",
       " 'time',\n",
       " 'place',\n",
       " 'meet',\n",
       " 'includ',\n",
       " 'agenda',\n",
       " 'inform',\n",
       " 'concern',\n",
       " 'manner',\n",
       " 'public',\n",
       " 'obtain',\n",
       " 'agenda',\n",
       " 'meet']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test clean_sentence on string with remove_acronyms=False\n",
    "clean_sentence(\"ABOUT\\nSCHOOLS\\nPROGRAMS\\nENROLL\\nPARENT LINKS\\nCOMMUNITY\\nCONTACT\\nMORE>>\\nBENNETT ACADEMY ACCELERATED HIGH SCHOOL\\xa0\\n\\u200b\\nBennett Accelerated High School\\xa0\\nBennett Accelerated High School will begin serving students in 9th and 10th grade in August 2018. Bennett Accelerated High School will offer the followng:\\xa0\\n\\u200b\\nA good school with good discipline\\nA well-organized learning environment with a friendly vibe\\nA place where teachers, staff, and students treat each other kindly and respectfully\\nAn environment with friends (and we add, good friends)\\nTeachers who care about their students and give them good help\\nCourses that teach them what they need\\nCore classes and several electives\\nSports\\nVision and Purpose\\nGrade 9 Course Descriptions\\nGrade 10 Course Descriptions\\nFAQ\\nEnroll Now\\n© 2012 by Twenty First\\xa0Century\\xa0\\n\\xa0 \\xa0 \\xa0Charter Schools\\n\\u200b\\nBennett Academy Middle School\\n\\u200b2930 W. Bethany Home Road. Phoenix, AZ\\xa085017\\nBennett Academy Primary School - Venture Site\\n1535 W.\\xa0Dunlap Ave. Phoenix, AZ 85021\\nWebmaster Login\\n\\ufeffPursuant to A.R.S. §38-431.02, Twenty First\\xa0Century\\xa0\\nSchools, Inc. hereby states that all notices of the meetings of Bennett Academy and Bennett Venture Site will be posted at each administrative office and on our website (www.bennettacademy.com). The location is open to the public Monday through Friday from 8:00 AM to 4:00 PM. Such notices will indicate the date, time and place of the meeting and will include an agenda or information concerning the manner in which the public may obtain an agenda for the meeting.\\n\\u200b\", slow_webclean = True, stemming = True, remove_acronyms=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define helper function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_webtext(ls):\n",
    "    \n",
    "    '''This function cleans and tokenizes sentences, removing punctuation and numbers and making words into lower-case stems.\n",
    "    Inputs: list of strings;\n",
    "    This function loops over all elements in the input list given, cleans the texts and returns one string'''\n",
    "        \n",
    "    global mpdo # Check if we're doing multiprocessing. If so, then mpdo=True\n",
    "    global sents_combined # Grants access to variable holding a list of lists of words, where each list of words represents a sentence in its original order (only relevant for this function if we're not using multiprocessing)\n",
    "    global pcount # Grants access to preprocessing counter\n",
    "    \n",
    "    known_pages = set() # Initialize list of known pages for a school\n",
    "    sents_combined = [] # Initialize list of all school's sentences\n",
    "    school_sentslist = []\n",
    "    #print('Parsing school #' + str(pcount)) # Print number of school being parsed\n",
    "\n",
    "    for s in ls: # Iterate over tuples in tuplist (list of tuples)\n",
    "        for chunk in s.split('\\n'): \n",
    "            for sent in nltk.sent_tokenize(chunk): # Tokenize chunk by sentences (in case >1 sentence in chunk)\n",
    "                #sent = clean_sentence(sent, fast=True) # Clean and tokenize sentence\n",
    "                sent = clean_sentence(sent)\n",
    "                if ((sent == []) or (len(sent) == 0)): # If sentence is empty, continue to next sentence without appending\n",
    "                    continue\n",
    "                \n",
    "                sents_combined.extend(sent) # add sent to school object\n",
    "                \n",
    "    school_sentslist.append(sents_combined) # add list of sentence to full list \n",
    "    \n",
    "    return sents_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean webtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows and cols:  (6103, 2)\n",
      "# duplicates by NCESSCH: 0\n",
      "\n",
      "Columns and # missing cases (if any): \n",
      "text_full\n",
      "NCESSCH\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(raw_filtered_data, sep=\"\\t\", encoding=\"utf-8\")[[\"text_full\", \"NCESSCH\"]]\n",
    "check_df(df, \"NCESSCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_full</th>\n",
       "      <th>NCESSCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['ut Reading Buddy\\nThe Reading Buddy program ...</td>\n",
       "      <td>1.001970e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Select a School...\\nSelect a School\\nKetchik...</td>\n",
       "      <td>2.001500e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['l Enrollment Homeschool\\nTitle IX: Assuring ...</td>\n",
       "      <td>2.001500e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Select a School...\\nSelect a School\\nAbbott ...</td>\n",
       "      <td>2.001800e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['eer Info\\nWCC\\nWPG\\nBrowse: \\nHome\\n» \\nWPG\\...</td>\n",
       "      <td>2.001800e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_full       NCESSCH\n",
       "0  ['ut Reading Buddy\\nThe Reading Buddy program ...  1.001970e+10\n",
       "1  ['Select a School...\\nSelect a School\\nKetchik...  2.001500e+10\n",
       "2  ['l Enrollment Homeschool\\nTitle IX: Assuring ...  2.001500e+10\n",
       "3  ['Select a School...\\nSelect a School\\nAbbott ...  2.001800e+10\n",
       "4  ['eer Info\\nWCC\\nWPG\\nBrowse: \\nHome\\n» \\nWPG\\...  2.001800e+10"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned  0  rows\n"
     ]
    }
   ],
   "source": [
    "ls_str = [] #initialize list for concatenated string for webtext per school\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ls_str.append(' '.join(clean_webtext(df['text_full'][i])))\n",
    "    if i%500 == 0:\n",
    "        print(\"Cleaned \", i, \" rows\")\n",
    "    \n",
    "df['text_full'] = ls_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next step: Merging!\n",
    "Now merge this cleaned text with the covariates from the previous version of the charter schools data (change only the `text_full` column)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
